{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using face + voiceprint + secret spoken phrase (which is used for both voice print and text) we can make a private key unique to you and deterministic."
      ],
      "metadata": {
        "id": "6A6C9uM-W_EW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax9QFGcbW44P",
        "outputId": "bd9ed3d5-c4df-45d9-c9d0-a401e0a8eb82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deterministic-rsa-keygen in /usr/local/lib/python3.8/dist-packages (0.0.1)\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.8/dist-packages (0.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Requirement already satisfied: pocketsphinx in /usr/local/lib/python3.8/dist-packages (5.0.0)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.8/dist-packages (3.9.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.8/dist-packages (0.25.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyplot (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pyplot\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install deterministic-rsa-keygen mtcnn matplotlib scipy librosa numpy pocketsphinx SpeechRecognition pydub pyplot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face metrics\n",
        "\n",
        "Make a rudimentary face detector, which looks for keypoints in a frame of a detected face (as a set of numbers). Scale these to a large enough Multi Dimensional Space and convert it into one value which can be used as part of a seed for a key, which is unique to a face.\n",
        "\n",
        "What we really want to do is put the face dimensions in a large vector space and get one number we can use as the seed - we can round things down on the way so that it is \"close\" even with differing values from the picture (borrowed from https://stackabuse.com/guide-to-multidimensional-scaling-in-python-with-scikit-learn/)"
      ],
      "metadata": {
        "id": "g2uOh2hRuJC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def face_to_stress(face_file):\n",
        "\n",
        "  from matplotlib import pyplot\n",
        "  from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "\n",
        "  # load image from file\n",
        "  pixels = pyplot.imread(face_file)\n",
        "\n",
        "  # create the detector, using default weights\n",
        "  detector = MTCNN()\n",
        "\n",
        "  # detect faces in the image\n",
        "  faces = detector.detect_faces(pixels)\n",
        "  face = faces[0]\n",
        "\n",
        "\n",
        "  from sklearn.manifold import MDS\n",
        "  from matplotlib import pyplot as plt\n",
        "  import sklearn.datasets as dt\n",
        "  import seaborn as sns         \n",
        "  import numpy as np\n",
        "  from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
        "  from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "  x_offset = face['box'][0]\n",
        "  y_offset = face['box'][1]\n",
        "\n",
        "\n",
        "  def round_ten(num):    \n",
        "    return round(num/10)*10\n",
        "\n",
        "  (left_eye_1, left_eye_2) = face['keypoints']['left_eye'] \n",
        "  (right_eye_1, right_eye_2) = face['keypoints']['right_eye']\n",
        "  (nose_1, nose_2) = face['keypoints']['nose']\n",
        "  (mouth_left_1, mouth_left_2) = face['keypoints']['mouth_left']\n",
        "  (mouth_right_1, mouth_right_2) = face['keypoints']['mouth_right']\n",
        "\n",
        "  X = np.array([[round_ten(left_eye_1-x_offset), round_ten(left_eye_2-y_offset)], \n",
        "                [round_ten(right_eye_1-x_offset), round_ten(right_eye_2-y_offset)], \n",
        "                [round_ten(nose_1-x_offset), round_ten(nose_2-y_offset)], \n",
        "                [round_ten(mouth_left_1-x_offset), round_ten(mouth_left_2-y_offset)], \n",
        "                [round_ten(mouth_right_1-x_offset), round_ten(mouth_right_2-y_offset)]])\n",
        "  mds = MDS(random_state=0)\n",
        "  X_transform = mds.fit_transform(X)\n",
        "\n",
        "  stress = mds.stress_\n",
        "  print(stress)\n",
        "\n"
      ],
      "metadata": {
        "id": "XBY13PhBuCpR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice print\n",
        "\n",
        "Everyone in the world can have a reasonably unique voice print which is hard to spoof, especially if combined with a secret phrase. librosa provides some simple utilities to calculate this. Using https://en.wikipedia.org/wiki/Linear_predictive_coding to provide utterance tolerant fingerprint (not secure enough to be non replayable - needs to be combined with a spoken secret)"
      ],
      "metadata": {
        "id": "b-nXvo0lu-1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def calculate_voiceprint(audio_file, num_coeffs=5):\n",
        "\n",
        "\n",
        "  # Calculate the linear predictive coefficients (LPCs) for the audio signal\n",
        "  audio, sr = librosa.load(audio_file)\n",
        "  lpcs = librosa.lpc(audio, num_coeffs)\n",
        "\n",
        "  def round_array(x, round_to):\n",
        "    # Round each element in the array to the nearest round_to value\n",
        "    rounded_array = [round(n * (1 / round_to)) * round_to for n in x]\n",
        "    return rounded_array\n",
        "\n",
        "  \n",
        "  return round_array(lpcs, 0.5)[:3]\n"
      ],
      "metadata": {
        "id": "hh83RXIYxP_c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice to text\n",
        "\n",
        "Here is some rudimentary voice to text to provide some extra signal"
      ],
      "metadata": {
        "id": "z-ABRjc0x_V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def voice_text(audio_file):\n",
        "  import speech_recognition as sr\n",
        "  from pydub import AudioSegment\n",
        "\n",
        "  audio = AudioSegment.from_file(audio_file, format=\"m4a\")\n",
        "  raw_data = audio.raw_data\n",
        "  audio_data = sr.AudioData(raw_data, audio.frame_rate, audio.sample_width)\n",
        "\n",
        "\n",
        "  r = sr.Recognizer()\n",
        "  text = r.recognize_sphinx(audio_data)\n",
        "  print(\"text detected: \" + text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "0CD34y4DyIAk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine into deterministic seed"
      ],
      "metadata": {
        "id": "ZyDU6PYlySVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_seed(face_file, voice_file):\n",
        "  return str(face_to_stress(face_file)) + str(calculate_voiceprint(voice_file)) + voice_text(voice_file)"
      ],
      "metadata": {
        "id": "IaZ7SHYfyWwV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encrypt from face and voice\n",
        "\n",
        "Use the determinisic seed to create a private key"
      ],
      "metadata": {
        "id": "N7NPN0R70LeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rsa import generate_key, encrypt, decrypt\n",
        "\n",
        "secret_key = generate_key(make_seed(\"test1.jpg\", \"voice_mic1.m4a\"))\n",
        "\n",
        "public_key = secret_key.publickey().exportKey(\"PEM\")\n",
        "\n",
        "# eg round trip:\n",
        "secret = encrypt(\"Hello World using face as key\", public_key)\n",
        "\n",
        "print(secret)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rQwz3940OC2",
        "outputId": "470a9a28-a1b8-4ec8-e339-834f291dadca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "9/9 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "0.07707175558959707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text detected: if my voice is my passport\n",
            "b'qCL+DYTW7+l+7oIPnmMnwr6fWm7Ci5YFdC/papv5PQI0l5yACGxYygPO28G0v3OO+svNiX0pZwreAofz0l9dBlcAb+XIJox+7x0afmBcWrD4oiKCHLCwHwgKs2LnH8O3y3Gk1SwmD2u2M0AmBUEB6Hxacolv0aNdDuQZzpg0wuKB9LVbfMPIL83P0+1IkYdXIY+46Ka1WVgzhIQ0A8pN7YkXW91izcIwC0wMLbkJwX4UyiffAFiqvYfACRkMmUENQ/AogznM4AEOGX/ONgZ7U4SneU/m2M0uIt+QsNplVt1GQxgYHa5gkGB8xZu1WKsi6qrmZtvZ99WHgvrxwe91Cg=='\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now will use a different photo and voice to ensure we can make the same key and then decrypt"
      ],
      "metadata": {
        "id": "8FE6Z1oC3i8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# using the other photo we can make the same key\n",
        "secret_key = generate_key(make_seed(\"test2.jpg\", \"voice_mic1.m4a\"))\n",
        "\n",
        "private_key = secret_key.exportKey(\"PEM\")\n",
        "\n",
        "# and we get the secret back (and can use alternative audio if we are clear enough)\n",
        "decrypt(secret, private_key)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m6ptAmY3m70",
        "outputId": "2d6f332a-76d5-460a-a9bd-a829464239db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 188ms/step\n",
            "1/1 [==============================] - 0s 203ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "3/3 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "0.12541588643659957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text detected: if my voice is my passport\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Hello World using face as key'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}