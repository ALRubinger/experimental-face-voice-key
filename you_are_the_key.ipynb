{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using face + voiceprint + secret spoken phrase (which is used for both voice print and text) we can make a private key unique to you and deterministic."
      ],
      "metadata": {
        "id": "6A6C9uM-W_EW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax9QFGcbW44P",
        "outputId": "3e8c3709-4958-4966-fd89-1dfb067566c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deterministic-rsa-keygen in /usr/local/lib/python3.8/dist-packages (0.0.1)\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.8/dist-packages (0.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Requirement already satisfied: pocketsphinx in /usr/local/lib/python3.8/dist-packages (5.0.0)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.8/dist-packages (3.9.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.8/dist-packages (0.25.1)\n",
            "Requirement already satisfied: pycryptodome>=3.10 in /usr/local/lib/python3.8/dist-packages (from deterministic-rsa-keygen) (3.16.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from mtcnn) (4.6.0.66)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from mtcnn) (2.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (5.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.28.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.8/dist-packages (from pocketsphinx) (0.4.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install deterministic-rsa-keygen mtcnn matplotlib scipy librosa numpy pocketsphinx SpeechRecognition pydub\n",
        "\n",
        "import urllib.request\n",
        "data_dir=\"https://raw.githubusercontent.com/TBD54566975/experimental-face-voice-key/main/data\"\n",
        "def download_file(filename):\n",
        "    urllib.request.urlretrieve(data_dir + \"/\" + filename, filename)\n",
        "\n",
        "download_file(\"test1.jpg\")\n",
        "download_file(\"test2.jpg\")\n",
        "download_file(\"voice_mic1.m4a\")\n",
        "download_file(\"voice_mic2.m4a\")\n",
        "download_file(\"voice_jo1.m4a\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face metrics\n",
        "\n",
        "Make a rudimentary face detector, which looks for keypoints in a frame of a detected face (as a set of numbers). Scale these to a large enough Multi Dimensional Space and convert it into one value which can be used as part of a seed for a key, which is unique to a face.\n",
        "\n",
        "What we really want to do is put the face dimensions in a large vector space and get one number we can use as the seed - we can round things down on the way so that it is \"close\" even with differing values from the picture (borrowed from https://stackabuse.com/guide-to-multidimensional-scaling-in-python-with-scikit-learn/)"
      ],
      "metadata": {
        "id": "g2uOh2hRuJC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def face_to_stress(face_file):\n",
        "\n",
        "  from matplotlib import pyplot\n",
        "  from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "\n",
        "  # load image from file\n",
        "  pixels = pyplot.imread(face_file)\n",
        "\n",
        "  # create the detector, using default weights\n",
        "  detector = MTCNN()\n",
        "\n",
        "  # detect faces in the image\n",
        "  faces = detector.detect_faces(pixels)\n",
        "  face = faces[0]\n",
        "\n",
        "\n",
        "  from sklearn.manifold import MDS\n",
        "  from matplotlib import pyplot as plt\n",
        "  import sklearn.datasets as dt\n",
        "  import seaborn as sns         \n",
        "  import numpy as np\n",
        "  from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
        "  from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "  x_offset = face['box'][0]\n",
        "  y_offset = face['box'][1]\n",
        "\n",
        "\n",
        "  def round_ten(num):    \n",
        "    return round(num/10)*10\n",
        "\n",
        "  (left_eye_1, left_eye_2) = face['keypoints']['left_eye'] \n",
        "  (right_eye_1, right_eye_2) = face['keypoints']['right_eye']\n",
        "  (nose_1, nose_2) = face['keypoints']['nose']\n",
        "  (mouth_left_1, mouth_left_2) = face['keypoints']['mouth_left']\n",
        "  (mouth_right_1, mouth_right_2) = face['keypoints']['mouth_right']\n",
        "\n",
        "  X = np.array([[round_ten(left_eye_1-x_offset), round_ten(left_eye_2-y_offset)], \n",
        "                [round_ten(right_eye_1-x_offset), round_ten(right_eye_2-y_offset)], \n",
        "                [round_ten(nose_1-x_offset), round_ten(nose_2-y_offset)], \n",
        "                [round_ten(mouth_left_1-x_offset), round_ten(mouth_left_2-y_offset)], \n",
        "                [round_ten(mouth_right_1-x_offset), round_ten(mouth_right_2-y_offset)]])\n",
        "  mds = MDS(random_state=0)\n",
        "  X_transform = mds.fit_transform(X)\n",
        "\n",
        "  stress = mds.stress_\n",
        "  print(stress)\n",
        "\n"
      ],
      "metadata": {
        "id": "XBY13PhBuCpR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice print\n",
        "\n",
        "Everyone in the world can have a reasonably unique voice print which is hard to spoof, especially if combined with a secret phrase. librosa provides some simple utilities to calculate this. Using https://en.wikipedia.org/wiki/Linear_predictive_coding to provide utterance tolerant fingerprint (not secure enough to be non replayable - needs to be combined with a spoken secret)"
      ],
      "metadata": {
        "id": "b-nXvo0lu-1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def calculate_voiceprint(audio_file, num_coeffs=5):\n",
        "\n",
        "\n",
        "  # Calculate the linear predictive coefficients (LPCs) for the audio signal\n",
        "  audio, sr = librosa.load(audio_file)\n",
        "  lpcs = librosa.lpc(audio, num_coeffs)\n",
        "\n",
        "  def round_array(x, round_to):\n",
        "    # Round each element in the array to the nearest round_to value\n",
        "    rounded_array = [round(n * (1 / round_to)) * round_to for n in x]\n",
        "    return rounded_array\n",
        "  \n",
        "  return round_array(lpcs, 0.5)[:3]\n"
      ],
      "metadata": {
        "id": "hh83RXIYxP_c"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try it out on 2 voice files"
      ],
      "metadata": {
        "id": "5J6FaSBJICVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculate_voiceprint(\"voice_mic1.m4a\"))\n",
        "print(calculate_voiceprint(\"voice_mic2.m4a\"))\n",
        "print(calculate_voiceprint(\"voice_jo1.m4a\"))"
      ],
      "metadata": {
        "id": "joVemX5YIE3z",
        "outputId": "e6bf950d-63d2-42df-ddf2-c4988b6ce466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, -1.0, 0.5]\n",
            "[1.0, -1.5, 0.5]\n",
            "[1.0, -1.5, 1.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice to text\n",
        "\n",
        "Here is some rudimentary voice to text to provide some extra signal"
      ],
      "metadata": {
        "id": "z-ABRjc0x_V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def voice_text(audio_file):\n",
        "  import speech_recognition as sr\n",
        "  from pydub import AudioSegment\n",
        "\n",
        "  audio = AudioSegment.from_file(audio_file, format=\"m4a\")\n",
        "  raw_data = audio.raw_data\n",
        "  audio_data = sr.AudioData(raw_data, audio.frame_rate, audio.sample_width)\n",
        "\n",
        "\n",
        "  r = sr.Recognizer()\n",
        "  text = r.recognize_sphinx(audio_data)\n",
        "  print(\"text detected: \" + text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "0CD34y4DyIAk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine into deterministic seed"
      ],
      "metadata": {
        "id": "ZyDU6PYlySVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_seed(face_file, voice_file):\n",
        "  return str(face_to_stress(face_file)) + str(calculate_voiceprint(voice_file)) + voice_text(voice_file)"
      ],
      "metadata": {
        "id": "IaZ7SHYfyWwV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encrypt from face and voice\n",
        "\n",
        "Use the determinisic seed to create a private key"
      ],
      "metadata": {
        "id": "N7NPN0R70LeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rsa import generate_key, encrypt, decrypt\n",
        "\n",
        "secret_key = generate_key(make_seed(\"test1.jpg\", \"voice_mic1.m4a\"))\n",
        "\n",
        "public_key = secret_key.publickey().exportKey(\"PEM\")\n",
        "\n",
        "# eg round trip:\n",
        "secret = encrypt(\"Hello World using face as key\", public_key)\n",
        "\n",
        "print(secret)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rQwz3940OC2",
        "outputId": "d1e4e55f-1a58-40e2-fae1-1b8f3d39a86e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 360ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "9/9 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "0.07707175558959707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text detected: if my voice is my passport\n",
            "b'fIdsXfmKRLlVyMF2OD7Gv/PBMr0aYSwiXWml0kd6oYYOy7jLHGZExllAmMtmXABCQO9VZFAfOlVlpiu1KDWirK+tBS8TiWzsG9LOd6IpHOuK+S6cVS+nGBXAiNu5MiPHzXC6LlVmNq7q02raYYv9RjitZYdvQJQnAtaRYv5QER5etuwAlDRc06xrAPYV8GuWRoCncOUufS1ojWEiveTW8H17ROkRahFuzAKivVkjDuA/xbmqDQgZnJbEsRbmCym35O6cxVJ3g77RTuZhOg3ad6ATXueQOsxAg1IcblG8OXAP70IehEwbiHVnrlElfyD06zs4afDibRIMsaquaMXsnQ=='\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now will use a different photo and voice to ensure we can make the same key and then decrypt"
      ],
      "metadata": {
        "id": "8FE6Z1oC3i8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# using the other photo we can make the same key\n",
        "secret_key = generate_key(make_seed(\"test2.jpg\", \"voice_mic1.m4a\"))\n",
        "\n",
        "private_key = secret_key.exportKey(\"PEM\")\n",
        "\n",
        "# and we get the secret back (and can use alternative audio if we are clear enough)\n",
        "decrypt(secret, private_key)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m6ptAmY3m70",
        "outputId": "b5ef27b8-581c-4016-9f5f-5612e04265e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f963a77daf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96388fa0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12541588643659957\n",
            "text detected: if my voice is my passport\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Hello World using face as key'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}