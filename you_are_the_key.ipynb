{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using face + voiceprint + secret spoken phrase (which is used for both voice print and text) we can make a private key unique to you and deterministic."
      ],
      "metadata": {
        "id": "6A6C9uM-W_EW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax9QFGcbW44P",
        "outputId": "3c0727e1-c34f-4ce2-b521-4db0f424be3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deterministic-rsa-keygen\n",
            "  Downloading deterministic_rsa_keygen-0.0.1-py3-none-any.whl (6.8 kB)\n",
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 28.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Collecting pocketsphinx\n",
            "  Downloading pocketsphinx-5.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.1 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 156 kB/s \n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pycryptodome>=3.10\n",
            "  Downloading pycryptodome-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from mtcnn) (4.6.0.66)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from mtcnn) (2.9.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (5.1.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.4.5-py3-none-any.whl (31 kB)\n",
            "Collecting requests>=2.19.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n",
            "Installing collected packages: requests, sounddevice, pycryptodome, SpeechRecognition, pydub, pocketsphinx, mtcnn, deterministic-rsa-keygen\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed SpeechRecognition-3.9.0 deterministic-rsa-keygen-0.0.1 mtcnn-0.1.1 pocketsphinx-5.0.0 pycryptodome-3.16.0 pydub-0.25.1 requests-2.28.1 sounddevice-0.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install deterministic-rsa-keygen mtcnn matplotlib scipy librosa numpy pocketsphinx SpeechRecognition pydub\n",
        "\n",
        "import urllib.request\n",
        "data_dir=\"https://raw.githubusercontent.com/TBD54566975/experimental-face-voice-key/main/data\"\n",
        "def download_file(filename):\n",
        "    urllib.request.urlretrieve(data_dir + \"/\" + filename, filename)\n",
        "\n",
        "download_file(\"test1.jpg\")\n",
        "download_file(\"test2.jpg\")\n",
        "download_file(\"voice_mic1.m4a\")\n",
        "download_file(\"voice_mic2.m4a\")\n",
        "download_file(\"voice_mic3.m4a\")\n",
        "\n",
        "download_file(\"voice_mic4.m4a\")\n",
        "download_file(\"voice_jo1.m4a\")\n",
        "download_file(\"oli_mic1.m4a\")\n",
        "download_file(\"oli_mic2.m4a\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face metrics\n",
        "\n",
        "Make a rudimentary face detector, which looks for keypoints in a frame of a detected face (as a set of numbers). Scale these to a large enough Multi Dimensional Space and convert it into one value which can be used as part of a seed for a key, which is unique to a face.\n",
        "\n",
        "What we really want to do is put the face dimensions in a large vector space and get one number we can use as the seed - we can round things down on the way so that it is \"close\" even with differing values from the picture (borrowed from https://stackabuse.com/guide-to-multidimensional-scaling-in-python-with-scikit-learn/)"
      ],
      "metadata": {
        "id": "g2uOh2hRuJC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def face_to_stress(face_file):\n",
        "\n",
        "  from matplotlib import pyplot\n",
        "  from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "\n",
        "  # load image from file\n",
        "  pixels = pyplot.imread(face_file)\n",
        "\n",
        "  # create the detector, using default weights\n",
        "  detector = MTCNN()\n",
        "\n",
        "  # detect faces in the image\n",
        "  faces = detector.detect_faces(pixels)\n",
        "  face = faces[0]\n",
        "\n",
        "\n",
        "  from sklearn.manifold import MDS\n",
        "  from matplotlib import pyplot as plt\n",
        "  import sklearn.datasets as dt\n",
        "  import seaborn as sns         \n",
        "  import numpy as np\n",
        "  from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
        "  from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "  x_offset = face['box'][0]\n",
        "  y_offset = face['box'][1]\n",
        "\n",
        "\n",
        "  def round_ten(num):    \n",
        "    return round(num/10)*10\n",
        "\n",
        "  (left_eye_1, left_eye_2) = face['keypoints']['left_eye'] \n",
        "  (right_eye_1, right_eye_2) = face['keypoints']['right_eye']\n",
        "  (nose_1, nose_2) = face['keypoints']['nose']\n",
        "  (mouth_left_1, mouth_left_2) = face['keypoints']['mouth_left']\n",
        "  (mouth_right_1, mouth_right_2) = face['keypoints']['mouth_right']\n",
        "\n",
        "  X = np.array([[round_ten(left_eye_1-x_offset), round_ten(left_eye_2-y_offset)], \n",
        "                [round_ten(right_eye_1-x_offset), round_ten(right_eye_2-y_offset)], \n",
        "                [round_ten(nose_1-x_offset), round_ten(nose_2-y_offset)], \n",
        "                [round_ten(mouth_left_1-x_offset), round_ten(mouth_left_2-y_offset)], \n",
        "                [round_ten(mouth_right_1-x_offset), round_ten(mouth_right_2-y_offset)]])\n",
        "  mds = MDS(random_state=0)\n",
        "  X_transform = mds.fit_transform(X)\n",
        "\n",
        "  stress = mds.stress_\n",
        "  print(stress)\n",
        "\n"
      ],
      "metadata": {
        "id": "XBY13PhBuCpR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice print\n",
        "\n",
        "Everyone in the world can have a reasonably unique voice print which is hard to spoof, especially if combined with a secret phrase. librosa provides some simple utilities to calculate this. Using https://en.wikipedia.org/wiki/Linear_predictive_coding to provide utterance tolerant fingerprint (not secure enough to be non replayable - needs to be combined with a spoken secret)"
      ],
      "metadata": {
        "id": "b-nXvo0lu-1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def calculate_voiceprint(audio_file, num_coeffs=200):\n",
        "\n",
        "\n",
        "  # Calculate the linear predictive coefficients (LPCs) for the audio signal\n",
        "  audio, sr = librosa.load(audio_file)\n",
        "  lpcs = librosa.lpc(audio, num_coeffs)\n",
        "\n",
        "  def round_vector(vector, precision):\n",
        "    rounded_vector = []\n",
        "    for i in range(len(vector)):\n",
        "      element = vector[i]\n",
        "      rounded_element = round(element / precision) * precision\n",
        "      rounded_vector.append(rounded_element)\n",
        "      precision += 0.2  # Increase precision by a small amount after each iteration, so we are less sensitive to future predictions\n",
        "    return rounded_vector\n",
        "  \n",
        "  return round_vector(lpcs, 0.5)[:6]\n"
      ],
      "metadata": {
        "id": "hh83RXIYxP_c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try it out on a few voice files\n",
        "\n"
      ],
      "metadata": {
        "id": "5J6FaSBJICVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mic1 = calculate_voiceprint(\"voice_mic1.m4a\")\n",
        "mic2 = calculate_voiceprint(\"voice_mic2.m4a\")\n",
        "\n",
        "mic3  = calculate_voiceprint(\"voice_mic3.m4a\")\n",
        "oli_mic1 = calculate_voiceprint(\"oli_mic1.m4a\")\n",
        "oli_mic2 = calculate_voiceprint(\"oli_mic2.m4a\")\n",
        "\n",
        "not_mic = calculate_voiceprint(\"voice_mic4.m4a\")\n",
        "\n",
        "jo = calculate_voiceprint(\"voice_jo1.m4a\")\n",
        "\n",
        "print(\"                    mic1\", mic1)\n",
        "print(\"                    mic2\", mic2)\n",
        "print(\"                    mic3\", mic3)\n",
        "print(\"Mic but different phrase\", not_mic)\n",
        "print(\"  Oli speaking like mic1\", oli_mic1)\n",
        "print(\"  Oli speaking like mic2\", oli_mic2)\n",
        "print(\"                      jo\", jo)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joVemX5YIE3z",
        "outputId": "a71917b9-7be7-4a38-ebce-67a54d6ef7a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    mic1 [1.0, -2.0999999999999996, 2.6999999999999997, -3.3, 5.199999999999999, -5.999999999999999]\n",
            "                    mic2 [1.0, -2.0999999999999996, 2.6999999999999997, -3.3, 5.199999999999999, -5.999999999999999]\n",
            "                    mic3 [1.0, -2.0999999999999996, 2.6999999999999997, -3.3, 5.199999999999999, -5.999999999999999]\n",
            "Mic but different phrase [1.0, -1.4, 1.7999999999999998, -2.1999999999999997, 2.5999999999999996, -2.9999999999999996]\n",
            "  Oli speaking like mic1 [1.0, -2.0999999999999996, 1.7999999999999998, -2.1999999999999997, 2.5999999999999996, -2.9999999999999996]\n",
            "  Oli speaking like mic2 [1.0, -1.4, 0.8999999999999999, -1.0999999999999999, 1.2999999999999998, -2.9999999999999996]\n",
            "                      jo [1.0, -2.0999999999999996, 2.6999999999999997, -4.3999999999999995, 5.199999999999999, -7.499999999999999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice to text\n",
        "\n",
        "Here is some rudimentary voice to text to provide some extra signal"
      ],
      "metadata": {
        "id": "z-ABRjc0x_V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def voice_text(audio_file):\n",
        "  import speech_recognition as sr\n",
        "  from pydub import AudioSegment\n",
        "\n",
        "  audio = AudioSegment.from_file(audio_file, format=\"m4a\")\n",
        "  raw_data = audio.raw_data\n",
        "  audio_data = sr.AudioData(raw_data, audio.frame_rate, audio.sample_width)\n",
        "\n",
        "\n",
        "  r = sr.Recognizer()\n",
        "  text = r.recognize_sphinx(audio_data)\n",
        "  print(\"text detected: \" + text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "0CD34y4DyIAk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine into deterministic seed"
      ],
      "metadata": {
        "id": "ZyDU6PYlySVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_seed(face_file, voice_file):\n",
        "  return str(face_to_stress(face_file)) + str(calculate_voiceprint(voice_file)) + voice_text(voice_file)"
      ],
      "metadata": {
        "id": "IaZ7SHYfyWwV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encrypt from face and voice\n",
        "\n",
        "Use the determinisic seed to create a private key"
      ],
      "metadata": {
        "id": "N7NPN0R70LeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rsa import generate_key, encrypt, decrypt\n",
        "\n",
        "secret_key = generate_key(make_seed(\"test1.jpg\", \"voice_mic1.m4a\"))\n",
        "\n",
        "public_key = secret_key.publickey().exportKey(\"PEM\")\n",
        "\n",
        "# eg round trip:\n",
        "secret = encrypt(\"Hello World using face as key\", public_key)\n",
        "\n",
        "print(secret)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rQwz3940OC2",
        "outputId": "0084c5a2-78d1-4097-c84d-753c2d28b28c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 370ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "9/9 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "0.07707175558959707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text detected: if my voice is my passport\n",
            "b'bjlIQDj0URzpm4JgsKWdKvdC5ifHjZKH+wghJgnmxZDkymmsxNf/8oLipEm+V7kAdpHCF1etCSrF3zSQfEOSEvc3QBTSHVXRj0vQpkcHyKi8THRCn3UhhXhvIFX6ltFpsVK3nufPSs4C8ACD9fzANJPk/AQBQjlYZrx3QzqJmJxY4xG3j0lId5OVV40AyQYUB2WaLTCY48vW8CbVdDw25rUxS/R4AvuGE5Ow/zh/0MsDLRF7KRNI84oR0PFpw3N/SgOoSYnZvHoG18JUGVIST5tdz0/+taUU3tAzxkcExmJMb9+24iWhyM+MOt2n08xiv+IIAm1pDlYZSbA+uxAGrQ=='\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now will use a different photo and voice to ensure we can make the same key and then decrypt"
      ],
      "metadata": {
        "id": "8FE6Z1oC3i8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# using the other photo we can make the same key\n",
        "secret_key = generate_key(make_seed(\"test2.jpg\", \"voice_mic1.m4a\"))\n",
        "\n",
        "private_key = secret_key.exportKey(\"PEM\")\n",
        "\n",
        "# and we get the secret back (and can use alternative audio if we are clear enough)\n",
        "decrypt(secret, private_key)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m6ptAmY3m70",
        "outputId": "ad118c1f-3afd-426b-a8b8-ee8ee6a81d31"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa18fec68b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa18fe444c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 110ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12541588643659957\n",
            "text detected: if my voice is my passport\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Hello World using face as key'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}